In survival analysis, the random variable $Y$ represents the time until an event of interest occurs (e.g., death or failure). The distribution of $Y$ is commonly described by the following fundamental functions:
\begin{enumerate}
    \item \textbf{Survival function}, which gives the probability that the event has not occurred by time $y$:
   $$
   S(y) = P(Y > y) = 1 - F(y).
   $$
   \item \textbf{Probability density function (PDF)}, which represents the instantaneous probability density of the event occurring exactly at time $y$:
   $$
   f(y) = \frac{d}{dy} F(y).
   $$
   \item \textbf{Hazard function}, defined as:
   $$
   h(y) = \lim_{\Delta y \to 0} 
   \frac{P(y \le Y < y + \Delta y \mid Y \ge y)}{\Delta y}
   = \frac{f(y)}{S(y)},
   $$
   It represents the instantaneous risk that an event occurs within an infinitesimally small time interval, given that the individual has survived up to time \( y \).
\end{enumerate}

The relationships among these functions are:
$$
f(y) = h(y) S(y),
\quad
S(y) = \exp\Big( - \int_0^y h(u) du \Big).
$$
Therefore, these three functions can be derived from each other and jointly describe the probabilistic behavior of the survival time.

\subsection{Parametric Survival Model} 
In practical analysis, for more convenient modeling and interpretation of survival data, it is common to make parametric assumptions for the hazard function $h(y)$, thereby constructing parametric survival models \cite{ibrahim2013bayesian}. This section introduces several typical parametric models and their corresponding Bayesian inference procedures.

\subsubsection{Exponential Model} \label{Exponential Model}
The simplest and most classical parametric survival model is the Exponential Model, which assumes that the hazard rate $h(y)$ remains constant over the entire time interval:
$$
h(y) = \lambda.
$$
This means that at any time $y$, the instantaneous risk of an event occurring for an individual does not change with survival time. Therefore, the exponential model has a simple structure and is easy to interpret and derive.

According to the basic relationships in survival analysis, we have:
$$
S(y) = \exp\Big( -\int_0^y h(u) du \Big) = \exp(-\lambda y), 
\quad 
f(y) = h(y) S(y) = \lambda \exp(-\lambda y).
$$
Thus, when the hazard rate is constant, the probability density function of the survival time is an exponential density.

Let the random sample of survival times be $Y = (Y_1, \ldots, Y_n)$, which are independently and identically distributed (i.i.d.) and follow an exponential distribution with parameter $\lambda$:
$$
Y_i \sim \text{Exponential}(\lambda), 
\quad 
\text{with density} ~ f_{Y_i}(y) = \lambda \exp(-\lambda y).
$$
where $\lambda$ represents the average event rate per unit time.

To flexibly capture individual heterogeneity, it is common in practical survival analysis to incorporate covariates by modeling the hazard rate $\lambda$ as a function of individual characteristics. The most widely used approach is to adopt a log-link function:
$$
\lambda_i = \exp(\mathbf{x}_i^\top \boldsymbol{\beta}),
\quad i = 1, \ldots, n,
$$
where $\mathbf{x}_i$ denotes the covariate vector for the $i$-th individual and $\boldsymbol{\beta}$ is the vector of regression coefficients to be estimated.

Under this specification, the exponential model naturally extends to the \textbf{exponential regression model}, and conditional on $\boldsymbol{\beta}$, the survival times $Y_i$ are assumed to be independently and identically distributed (i.i.d.). For right-censored observations $(y_i, \nu_i)$, the likelihood function is given by:
\begin{align*}
L(\boldsymbol{\beta} | D)
&= \prod_{i=1}^n 
\big[ f(y_i | \boldsymbol{\beta}) \big]^{\nu_i}
\big[ S(y_i | \boldsymbol{\beta}) \big]^{1 - \nu_i} \\
&= \prod_{i=1}^n 
\big[ \lambda_i \exp(-\lambda_i y_i) \big]^{\nu_i}
\big[ \exp(-\lambda_i y_i) \big]^{1 - \nu_i} \\
&= \prod_{i=1}^n 
\lambda_i^{\nu_i} 
\exp(-\lambda_i y_i) \\
&= \prod_{i=1}^n 
\exp\big( \nu_i \mathbf{x}_i^\top \boldsymbol{\beta} \big)
\exp\big( - y_i \exp(\mathbf{x}_i^\top \boldsymbol{\beta}) \big).
\end{align*}
In the absence of prior knowledge, a common choice for the prior distribution of $\boldsymbol{\beta}$ is either an improper uniform prior, $\pi(\boldsymbol{\beta}) \propto 1$, or a multivariate normal prior:
$$
\boldsymbol{\beta} \sim N(\boldsymbol{\mu}_0, \Sigma_0).
$$
Here, we adopt the normal prior as an example. The posterior distribution (up to a normalizing constant) is then:
$$
\pi(\boldsymbol{\beta} | D)
\propto L(\boldsymbol{\beta} | D) \, \pi(\boldsymbol{\beta})
= \prod_{i=1}^n 
\exp\big( \nu_i \mathbf{x}_i^\top \boldsymbol{\beta} 
- y_i \exp(\mathbf{x}_i^\top \boldsymbol{\beta}) \big)
\times \exp\Big( -\frac{1}{2} (\boldsymbol{\beta} - \boldsymbol{\mu}_0)^\top \Sigma_0^{-1} (\boldsymbol{\beta} - \boldsymbol{\mu}_0) \Big).
$$
Taking the logarithm, the log-posterior kernel is:
$$
\log \pi(\boldsymbol{\beta} | D) 
= \sum_{i=1}^n \big[ \nu_i \mathbf{x}_i^\top \boldsymbol{\beta} 
- y_i \exp(\mathbf{x}_i^\top \boldsymbol{\beta}) \big]
- \frac{1}{2} (\boldsymbol{\beta} - \boldsymbol{\mu}_0)^\top \Sigma_0^{-1} (\boldsymbol{\beta} - \boldsymbol{\mu}_0) + \text{const}.
$$
Clearly, this posterior distribution does not admit a closed-form solution and can be sampled using MCMC methods. According to \cite{gilks1992adaptive}, if the posterior distribution is log-concave with respect to the parameter, adaptive rejection sampling (ARS) can be efficiently employed. By verifying that the second derivative of the log-posterior kernel is non-positive, it follows that when the prior is normal, the posterior distribution for the exponential regression model is log-concave, and hence ARS can be safely applied for efficient sampling.




\subsubsection{Weibull Model} \label{Weibull Model}
The Weibull model is a natural generalization of the exponential model and is suitable for describing scenarios where the hazard rate changes monotonically over time. Compared to the exponential model, which assumes a constant hazard rate, the Weibull model introduces a shape parameter $\alpha$, allowing the hazard rate $h(y)$ to increase or decrease with survival time $y$, providing greater flexibility to capture realistic survival or failure patterns.

The hazard function, probability density function, and survival function are given by:
$$
h(y) = \alpha \gamma y^{\alpha - 1}, 
\quad 
f(y) = \alpha \gamma y^{\alpha - 1} \exp(-\gamma y^{\alpha}), 
\quad 
S(y) = \exp(-\gamma y^{\alpha}),
\quad \gamma > 0,
$$
where $\alpha$ is the shape parameter and $\gamma = \exp(\lambda)$ is the scale parameter. When $\alpha > 1$, the hazard rate increases over time (indicating an aging effect); when $\alpha < 1$, the hazard rate decreases over time (indicating early failure); and when $\alpha = 1$, the Weibull model reduces to the exponential model.

Similar to the exponential case, suppose the survival time sample $Y = (Y_1, \ldots, Y_n)$ is independently and identically distributed according to a common Weibull distribution. To further incorporate individual covariate effects, the scale parameter can be modeled as:
$$
\gamma_i = \exp(\mathbf{x}_i^\top \boldsymbol{\beta}),
\quad i = 1, \ldots, n,
$$
where $\mathbf{x}_i$ denotes the covariate vector and $\boldsymbol{\beta}$ is the vector of regression coefficients. The functional forms of the hazard and density remain unchanged, with $\gamma$ replaced by $\gamma_i$.
Assuming independent samples and right-censoring, the full likelihood function is:
$$
L(\boldsymbol{\beta}, \alpha)
= \prod_{i=1}^n 
\big[ f(y_i) \big]^{\nu_i} 
\big[ S(y_i) \big]^{1 - \nu_i}
= \prod_{i=1}^n 
\big[ \alpha \gamma_i y_i^{\alpha - 1} \big]^{\nu_i} 
\exp(-\gamma_i y_i^\alpha).
$$
For the prior specification, $\boldsymbol{\beta}$ can be assigned the same normal prior as in the exponential regression case, while the shape parameter $\alpha$ is commonly assigned a Gamma prior:
$$
\boldsymbol{\beta} \sim N(\boldsymbol{\mu}_0, \Sigma_0), 
\quad 
\alpha \sim \text{Gamma}(a_0, b_0).
$$
Assuming $\boldsymbol{\beta}$ and $\alpha$ are conditionally independent a priori, the joint posterior distribution (up to a normalizing constant) is:
$$
\pi(\boldsymbol{\beta}, \alpha | D)
\propto L(\boldsymbol{\beta}, \alpha)
\, \pi(\boldsymbol{\beta})
\, \pi(\alpha).
$$
Taking logarithms yields the log-posterior kernel:
$$
\log \pi(\boldsymbol{\beta}, \alpha | D)
= \sum_{i=1}^n 
\big[
\nu_i \log \alpha + \nu_i \mathbf{x}_i^\top \boldsymbol{\beta} 
+ \nu_i (\alpha - 1) \log y_i 
- \exp(\mathbf{x}_i^\top \boldsymbol{\beta}) y_i^\alpha
\big]
+ \log \pi(\boldsymbol{\beta}) + \log \pi(\alpha) + \text{const}.
$$
As in the exponential regression case, this posterior distribution does not have a closed form and must be sampled numerically. It can be shown that, given the normal prior for $\boldsymbol{\beta}$ and Gamma prior for $\alpha$, the log-posterior is concave with respect to each parameter, satisfying the log-concavity condition and making ARS or Gibbs sampling applicable for efficient inference.

\subsubsection{Extreme Value Model}
The Extreme Value (EV) model can be viewed as a reparameterization of the Weibull model in the log-time domain, which reformulates the hazard function as an exponential-linear form in log time, facilitating direct integration of covariates.

Specifically, if the survival time $T \sim \text{Weibull}(\alpha, \gamma)$, define:
$$
Y = \log T.
$$
Then,
$$
P(Y \le y) 
= P(\log T \le y)
= P(T \le e^y)
= F_T(e^y)
= 1 - \exp\big( - \gamma e^{\alpha y} \big).
$$
Therefore, the cumulative distribution function (CDF) for the EV model is:
$$
F(y) = 1 - \exp\big( - \exp(\lambda + \alpha y) \big), 
\quad \text{where}~\lambda = \log \gamma.
$$
It follows that:
$$
\begin{aligned}
S(y) &= \exp\big( - \exp(\lambda + \alpha y) \big),\\
f(y) &= \alpha \exp(\lambda + \alpha y) \exp\big( - \exp(\lambda + \alpha y) \big),\\
h(y) &= \alpha \exp(\lambda + \alpha y).
\end{aligned}
$$
Compared to the power-form hazard in the Weibull model, the hazard in the EV model becomes exponential-linear with respect to log time and covariates, making the derivation simpler, the interpretation more straightforward, and the link with covariates naturally linear. In this formulation, $Y \in (-\infty, +\infty)$ is no longer constrained to be positive.

With covariates, the location parameter is specified as:
$$
\lambda_i = \mathbf{x}_i^\top \boldsymbol{\beta}, 
\quad i = 1, \ldots, n.
$$
Accordingly,
$$
f(y_i) = \alpha \exp(\alpha y_i + \lambda_i) \exp\big( -\exp(\alpha y_i + \lambda_i) \big), 
\quad
S(y_i) = \exp\big( -\exp(\alpha y_i + \lambda_i) \big).
$$
The observations $\{ Y_i, \nu_i \}_{i=1}^n$ are assumed to be independent and identically distributed (i.i.d.).

The likelihood function is then:
$$
L(\boldsymbol{\beta}, \alpha) 
= \prod_{i=1}^n 
\big[ f(y_i) \big]^{\nu_i} 
\big[ S(y_i) \big]^{1 - \nu_i}
= \prod_{i=1}^n 
\big[ \alpha \exp(\alpha y_i + \lambda_i) \big]^{\nu_i} 
\exp\big( -\exp(\alpha y_i + \lambda_i) \big).
$$
The prior distributions are the same as for the Weibull model:
$$
\boldsymbol{\beta} \sim N(\boldsymbol{\mu}_0, \Sigma_0), 
\quad 
\alpha \sim \text{Gamma}(a_0, b_0).
$$
The joint posterior (up to a normalizing constant) is:
$$
\pi(\boldsymbol{\beta}, \alpha | D) 
\propto L(\boldsymbol{\beta}, \alpha)
\, \pi(\boldsymbol{\beta}) 
\, \pi(\alpha).
$$
The log-kernel of the posterior is:
$$
\log \pi(\boldsymbol{\beta}, \alpha | D)
= \sum_{i=1}^n 
\big[
\nu_i \log \alpha + \nu_i \alpha y_i + \nu_i \lambda_i - \exp(\alpha y_i + \lambda_i)
\big]
+ \log \pi(\boldsymbol{\beta}) + \log \pi(\alpha) + \text{const}.
$$
It can be shown that the Hessian of this log-posterior with respect to both $\boldsymbol{\beta}$ and $\alpha$ is non-positive definite, implying log-concavity, which allows safe and efficient inference using ARS or Gibbs sampling in practice.
