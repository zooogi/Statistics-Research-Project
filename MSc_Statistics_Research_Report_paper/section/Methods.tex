


\subsection{Why be Bayesian?}\label{Why Bayesian}
When we first encounter statistical modelling, we often focus on finding the “best parameter estimate,” such as using Maximum Likelihood Estimation (MLE), the Method of Moments, or Least Squares regression as common non-Bayesian approaches to fit the model to the data~\cite{van2021bayesian}. This works well in many tasks, but in practice, we also need to know how uncertain that estimate is~\cite{gelman1995bayesian}. 

In situations with a limited sample size, complex structures, or high censoring rates, classical estimators can be biased, and their uncertainty is hard to quantify~\cite{van2021bayesian, ibrahim2013bayesian}. For example, in Efron’s leukemia survival study~\cite{Efron01091977}, only $21$ patients were included, and over half were right-censored. The Cox model estimated a hazard ratio of about $2.0$, but with a standard error nearly as significant as the estimate, giving a wide 95\% CI ($\approx$0.8–5.0) and making risk assessment unreliable. This illustrates how high censoring and small samples can destabilise classical estimators, a challenge frequently encountered in survival studies where complex or partially unobserved mechanisms may drive censoring. Such situations are difficult for classical methods but naturally handled in a Bayesian framework.

Bayesian methods address this limitation by treating parameters as random variables whose uncertainty is described by a probability distribution~\cite{gelman1995bayesian}. This allows prior information and data evidence to be combined through
$$
\text{Posterior}(\theta \mid D)
\propto
\text{Likelihood}( D \mid \theta)
\times
\text{Prior}(\theta),
$$
yielding a full posterior distribution rather than a single estimate. This reframes inference from “finding the right number” to dynamically updating and refining beliefs, providing not only point estimates but also credible intervals and posterior predictive distributions for a complete picture of uncertainty~\cite{gelman1995bayesian}.

The flexibility of this approach makes it applicable from simple mean estimation and regression to hierarchical, time-series, and deep generative models~\cite{carlin1997bayes}. In survival analysis, where censoring is common, Bayesian models naturally accommodate it within the likelihood~\cite{bartovs2022informed}. When sample sizes are small or censoring rates are high, priors can stabilise estimation by incorporating historical data or expert knowledge~\cite{gelman1995bayesian}. Beyond parameter estimation, Bayesian inference also provides a principled framework for model checking: by drawing parameters from the posterior and generating replicated datasets through posterior predictive simulation, one can directly assess whether the model captures the structural features of the observed data~\cite{https://doi.org/10.1002/ecm.1314, cho2025nonlinear}. Whether using parametric or non-parametric approaches, Bayesian inference offers a structured, interpretable, and extensible framework~\cite{van2021bayesian}. 

Later in this study, we will build on this Bayesian foundation to introduce modelling extensions that explicitly account for censoring mechanisms, allowing us to address limitations of standard survival models in a principled way.


%%%%%今天就到这，然后接下来你要把你做的那些衔接看一看，合不合理！然后接着修改老师的意见！！！
%%%%反正你的结论肯定要大改的，尽量能改完，因为你还要跑模型！

\subsection{Fundamentals of Survival Analysis} \label{Fundamentals of Survival Analysis}
Given the limitations of classical methods discussed in the previous section, particularly under high censoring and small sample sizes, we adopt a Bayesian framework for survival analysis. Before introducing the proposed model, we briefly review the core quantities in survival analysis, which will serve as the foundation for our methodological development~\cite{kleinbaum1996survival}.

In survival analysis, let the true event time for subject $i=1,\dots,n$ be the random variable $T_i\ge 0$. Assume
$$
T_1,\ldots,T_n \stackrel{\text{i.i.d.}}{\sim} F_T,\qquad \text{support }[0,\infty).
$$
If right censoring is present, introduce a censoring time $C_i\ge 0$ and adopt the independent censoring assumption~\cite{kalbfleisch2002statistical}: for each $i$, $T_i\perp C_i$, and observations are independent across subjects; the actually observed data are
$$
Y_i=\min(T_i,\;C_i),\qquad \delta_i=\mathbf 1\{T_i\le C_i\}.
$$
The basic functions that describe the distribution of $T$ are:
\begin{enumerate}
    \item \textbf{Survival function}, the probability that the event has not occurred after time $t$
   \begin{equation}
       S_T(t)=\mathbb P(T>t)=1-F_T(t),\qquad t\ge 0,
   \end{equation}
   where $F_T(t)=\mathbb P(T\le t)$. The function $S_T(\cdot)$ is non-increasing in $t$, is typically taken to be right-continuous, and satisfies $S_T(0^-)=1$~\cite{ibrahim2013bayesian}.
   \item \textbf{Probability density function (PDF)}, the instantaneous density of failure at time $t$ (when $F_T$ is absolutely continuous with respect to Lebesgue measure)
   \begin{equation}
   f_T(t)=\frac{d}{dt}F_T(t)=-\frac{d}{dt}S_T(t)
  \end{equation}
\noindent\textit{Holds at differentiable points / almost everywhere}~\cite{ibrahim2013bayesian,kleinbaum1996survival}.
   \item \textbf{Hazard function}, defined by
   \begin{equation}
        h_T(t)=\lim_{\Delta\downarrow 0}\frac{\mathbb P\big(t\le T<t+\Delta\ \big|\ T\ge t\big)}{\Delta}
          =\frac{f_T(t)}{S_T(t)}\quad(\text{when }S_T(t)>0),
   \end{equation}
   which quantifies the instantaneous failure rate given survival up to $t$~\cite{kalbfleisch2002statistical, ibrahim2013bayesian}. Define the cumulative hazard \begin{equation}
       H_T(t)=\int_0^{t} h_T(u)\,du.
   \end{equation}
\end{enumerate}

Their relationships (under the usual regularity conditions~\cite{kleinbaum1996survival}: $S_T(t)$ is positive, continuous and differentiable on its domain; $h_T(t)$ is locally integrable; and $H_T(t)$ is finite for all $t$) are
\begin{equation}
    f_T(t)=h_T(t)\,S_T(t),\qquad
S_T(t)=\exp\!\Big(-\!\int_0^{t} h_T(u)\,du\Big)=\exp\!\big(-H_T(t)\big),
\label{eq:4}
\end{equation}
and, at differentiable points,
\begin{equation}
    h_T(t)=-\frac{d}{dt}\log S_T(t).
\end{equation}
These three functions are mathematically redundant. Knowing one determines the others, but having all of them is useful for interpretation and application~\cite{kalbfleisch2002statistical}.





\subsection{Parametric Exponential Model} \label{Exponential Model}
%%%%Bridge
In the previous section, we introduced the general setup of survival analysis and the motivation for Bayesian inference. Here, we take the exponential model as a worked example because its simplicity and closed-form properties make it easier to focus on the role of the censoring mechanism without additional model complexity~\cite{kalbfleisch2002statistical, lawless2011statistical}. This clarity will be useful later when introducing an observation-window parameter $A$ to examine its influence on the censoring structure. 

%%%General survival likelihood and Bayesian formulation
\subsubsection{General Survival Likelihood and Bayesian Formulation}
In general, for any parametric survival model with density $f_T(t\mid\theta)$ and survival function $S_T(t\mid\theta)$, the likelihood is
\begin{equation}
L( D \mid \theta)
= \prod_{i=1}^n
\big[ f_T(y_i \mid \theta) \big]^{\delta_i}
\big[ S_T(y_i \mid \theta) \big]^{1 - \delta_i},
\label{eq:8}
\end{equation}
where $\delta_i=1$ indicates an observed event for subject $i$ (contributing $f_T(y_i\mid\theta)$) and $\delta_i=0$ indicates right-censoring (contributing $S_T(y_i\mid\theta)$). Here $y_i$ denotes the observed time $Y_i=\min(T_i,C_i)$~\cite{ibrahim2013bayesian}. 

This formulation coherently combines exact failure times and censored observations under the independent censoring assumption, forming the basis for frequentist estimation approaches and, in the Bayesian framework, being further combined with a prior to yield the posterior distribution~\cite{kalbfleisch2002statistical}.

In the Bayesian framework, the likelihood is combined with a prior $\pi(\theta)$ to form the (unnormalized) posterior
\begin{equation}
\pi(\theta \mid D)
\propto
L(D \mid \theta)\times \pi(\theta),
\end{equation}
which can then be summarised through posterior means, medians, credible intervals, or used for posterior predictive checks~\cite{ibrahim2013bayesian}. The prior $\pi(\theta)$ can be weakly informative (e.g., $\pi(\theta) \propto 1$) or informative, incorporating prior studies or expert knowledge~\cite{carlin1997bayes}. This general formulation applies to any survival model and provides the foundation for the special case considered below~\cite{bernardo1994bayesian}.

%%Exponential Model
\subsubsection{Specialisation to the Exponential Model}
\label{指数模型贝叶斯推断过程}
The exponential model assumes a constant hazard rate
\begin{equation}
h_T(t)=\lambda,\qquad t\ge 0,\ \ \lambda>0 .
\end{equation}
This implies that the instantaneous event risk remains unchanged regardless of how long the subject has survived~\cite{lawless2011statistical, ibrahim2013bayesian}. For instance, a light bulb with a constant failure risk at any moment can be described by a single parameter $\lambda$, without modelling time-varying risks, which greatly simplifies both inference and computation~\cite{lawless2011statistical}.

Using Equation~\eqref{eq:4} from the Section~\ref{Fundamentals of Survival Analysis}, and assuming $h_T(t) = \lambda$, the survival and density functions of the exponential model~\cite{kleinbaum1996survival} are given by
\begin{equation}
    S_T(t) = \exp\Big( -\displaystyle\int_0^t h_T(u), du \Big)=\exp(-\lambda t), \quad t \ge 0
    \label{St_exp}
\end{equation}
\begin{equation}
    f_T(t) = h_T(t)\, S_T(t)=\lambda \exp(-\lambda t), \quad t \ge 0
    \label{ft_exp}
\end{equation}

Substituting $S_T(t)$ and $f_T(t)$ into the general likelihood~\eqref{eq:8} yields~\cite{ibrahim2013bayesian}
\begin{align}
L(D \mid \lambda)
&=\prod_{i=1}^{n}
\big[\lambda \exp(-\lambda y_i)\big]^{\delta_i}
\big[\exp(-\lambda y_i)\big]^{1-\delta_i}, \quad y_i \ge 0 \\
&=
\prod_{i=1}^{n}
\lambda^{\delta_i}
\exp\left(
-\lambda y_i (\delta_i + 1 - \delta_i)
\right) \\
&=
\left(
\prod_{i=1}^{n}
\lambda^{\delta_i}
\right)
\exp\left(
-\lambda \sum_{i=1}^{n} y_i
\right)\\
&=
\lambda^{\sum_{i=1}^{n} \delta_i}
\exp\left(
-\lambda \sum_{i=1}^{n} y_i
\right)\\
&\propto
\text{Gamma}
\left(
\sum_{i=1}^{n} \delta_i + 1,\ \sum_{i=1}^{n} y_i
\right).
\end{align}
For the exponential model, we first assume a Gamma($\alpha, \beta$) prior for the rate parameter $\lambda \ge 0$. This prior belongs to the conjugate family for the exponential likelihood, which allows the posterior to be derived in closed form and facilitates analytical exposition~\cite{kalbfleisch2002statistical}.

Under this assumption, the (unnormalized) posterior is
\begin{align}
p(\lambda\mid D)
\label{eq:16}
&\propto \lambda^{\sum \delta_i}
\exp\Big(-\lambda \sum y_i\Big)\, \pi_\lambda(\lambda)\,\\
&\propto
\lambda^{\sum \delta_i}
\exp\Big(-\lambda \sum y_i\Big)
\times
\lambda^{\alpha - 1}
\exp(-\beta \lambda)\\
&=\lambda^{\sum \delta_i + \alpha - 1}
\exp \left( - \lambda \big(\sum y_i + \beta\big) \right) \\
&\sim
\text{Gamma}
\left(
\sum_{i=1}^{n} \delta_i + \alpha,\ \sum_{i=1}^{n} y_i + \beta
\right)
\label{eq:17}
\end{align}

\subsubsection{Example: Posterior Computation via MCMC}
Although the posterior for the exponential model with a Gamma$(\alpha,\beta)$ prior can be obtained analytically (Eq.~\ref{eq:17}), numerical methods such as Markov Chain Monte Carlo (MCMC) are often preferred for more complex models~\cite{robert2007bayesian,ibrahim2013bayesian}. As a demonstration, we use the Veteran dataset from the \texttt{survival} package in R~\cite{survival-package}, which contains survival times from a clinical trial of lung cancer patients. Here, we apply a weakly informative yet conjugate Gamma$(0.001,0.001)$ prior to illustrate the computation.

The computation is implemented in Stan, a probabilistic programming language for Bayesian inference that uses efficient algorithms such as Hamiltonian Monte Carlo to sample from complex posteriors~\cite{JSSv076i01}. MCMC produces draws from the posterior distribution; when the chains converge and mix well, the empirical distribution of these draws approximates the true posterior arbitrarily closely~\cite{https://doi.org/10.1111/2041-210X.12681}.

\begin{example}
Figure~\ref{fig:exp veteran} compares the posterior samples for $\lambda$ (histogram) with the analytic Gamma posterior (red curve), showing excellent agreement and confirming that histograms or density estimates of MCMC draws are valid representations of the underlying distribution.
\begin{figure}[H]
    \centering
    \includegraphics[height=7.5cm, width=0.55\textwidth]{images/veteran_post_lam.png}
    \caption{{\small Posterior distribution of $\lambda$ from MCMC samples (histogram) and analytic Gamma posterior (red curve) for the Veteran dataset.}}
    \label{fig:exp veteran}
\end{figure}
\end{example}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\subsection{Model Checking}\label{sec:model checking}
\input{MSc_Statistics_Research_Report_paper/section/Methods_subsection/model checking}
\subsection{Impact of the Survey-Length Parameter \texorpdfstring{$A$}{A} on Censoring and Model Fit}
\label{Impact of A}
\input{MSc_Statistics_Research_Report_paper/section/Methods_subsection/Choosing and Interpreting A}
\subsection{Bayesian Estimation of \texorpdfstring{$A$}{A} in Exponential Censoring Models}
\label{A_bayes}
\input{MSc_Statistics_Research_Report_paper/section/Methods_subsection/Bayesian Estimation of $A$ in Exponential Censoring Models}
\subsection{Identifiability and Posterior Structure of \texorpdfstring{$\lambda$}{lambda} and \texorpdfstring{$A$}{A}}
\input{MSc_Statistics_Research_Report_paper/section/Methods_subsection/Identifiability and Posterior Structure of lambda and A}














