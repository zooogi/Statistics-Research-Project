The analysis of survival time has a long intellectual history, from the population censuses of the Western Han dynasty in China and the “Yellow Registers” of the Ming dynasty~\cite{von2012household}, to John Graunt’s mortality tables during the London plague in the 17th century~\cite{doi:10.1177/09677720221079826}. These efforts, though rudimentary, already showed how survival data could inform decisions. Modern survival analysis, however, took shape in the mid-20th century with the emergence of parametric, nonparametric, and semiparametric approaches. Parametric models such as the exponential or Weibull~\cite{ibrahim2013bayesian} were among the earliest, assuming specific hazard forms that make inference straightforward but rely on restrictive distributional assumptions. The Kaplan–Meier estimator (1958)~\cite{liu2012survival, kleinbaum1996survival} then introduced a fully nonparametric method for censored data, providing intuitive survival curves without distributional assumptions, though it cannot incorporate covariates. The Cox proportional hazards model (1972)~\cite{Efron01091977, liu2012survival} built on this by combining covariate effects with an unspecified baseline hazard, becoming the standard in biomedical research despite its reliance on the proportional hazards assumption. Together, these models established the classical toolbox that remains central to medicine, epidemiology, and reliability engineering.

Yet this toolbox has limitations. Traditional inference via maximum or partial likelihood~\cite{bartovs2022informed, kalbfleisch2002statistical} provides only point estimates, which can be highly unstable under heavy censoring or small samples, and does not naturally convey uncertainty. While large-sample theory guarantees consistency, in practice such estimates can be misleading when event counts are low. Bayesian approaches~\cite{gelman1995bayesian} address these issues by producing full posterior distributions, allowing uncertainty to be quantified and prior knowledge to be incorporated, which is particularly valuable in small-sample or complex settings. Beyond estimation, they enable posterior predictive model checking~\cite{gelman1995bayesian, https://doi.org/10.1002/ecm.1314}
, which asks not just whether a model fits observed data but whether it reproduces the structural features that generated them. This shift has been crucial in revealing weaknesses of otherwise standard models.

One such weakness concerns administrative censoring. In most applications, the survey or observation window is treated as an external design feature~\cite{barrajón2020effectrightcensoringbias, bartovs2022informed}. But model checking shows it to be central: if the window is too short, events are prematurely censored; if too long, implausible long tails emerge~\cite{barrajón2020effectrightcensoringbias}. In other words, the observation window is not a neutral background assumption, but a structural parameter whose neglect can distort inference.

As a motivating case, we analyze a publicly available employee turnover dataset, which records the tenure of 1,129 employees and whether they exited during the survey period, to illustrate how censoring and the observation window shape inference. While the dataset is not the primary object of study, it provides a concrete case where censoring and observation windows crucially shape inference. It raises three motivating questions: whether the exponential survival model with its constant hazard is adequate to explain turnover durations, how the observation window influences censoring and estimation, and how Bayesian model checking can reveal structural issues and guide model extensions. To address these, we develop a Bayesian survival framework that incorporates the observation window as an estimable parameter, studies its identifiability and posterior structure, and evaluates its role in shaping inference, while briefly outlining alternative baselines suggested by the diagnostics.
